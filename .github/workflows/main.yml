name: ML Pipeline Automation

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:  # Allows manual execution from GitHub UI

jobs:
  preprocess-train:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt  # Ensure all dependencies from requirements.txt are installed
          pip install fsspec gcsfs pandas google-cloud-bigquery pyarrow db-dtypes

      - name: Authenticate with Google Cloud
        run: |
          echo '${{ secrets.GCS_HOUSE_PREDICT }}' | jq '.' > gcp_key.json
          gcloud auth activate-service-account --key-file=gcp_key.json
          export GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp_key.json
          echo "GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp_key.json" >> $GITHUB_ENV

      - name: Run Data Load Script
        run: python src/data_load.py

      - name: Train Model
        run: python train.py --model-output-path model

      - name: Save Model Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: model/

  deploy-app:
    needs: preprocess-train
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Download Trained Model
        uses: actions/download-artifact@v4
        with:
          name: trained-model
          path: model/

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas scikit-learn joblib numpy streamlit
          pip install db-dtypes google-cloud-bigquery[pandas]
          pip install gcsfs

      - name: Run Streamlit App
        run: streamlit run app.py
